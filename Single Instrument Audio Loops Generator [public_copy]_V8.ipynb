{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "M26Ux83geyRW"
      ],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Guide:\n",
        "1.   Execute SETUP (1ST TIME).\n",
        "2.   INSTALL the LIBRARIES for the GENERATION MODELS that you wish to use: AudioLDM2-Music + StableAudio Open share the same libraries. REQUIREMENTS: Login to HuggingFace is necessary to use the aforementioned models (an API key is needed, is free and can be generated here https://huggingface.co/settings/tokens), CUDA drivers and a CUDA compatible architecture is needed (e.g. Google Collabs GPUs, i suggest NVIDIA A100 for music generation inference tasks). Could also work with freely available T4 card, but the memory is almost always not enough to carry out the inference process. MusicGen libraries will take some time to install, much more than the other 2 models.\n",
        "3. move on UPLOAD: first upload the musical idea on which you want to build on, can be either .mp3 OR .wav (only these 2 formats are acepted for now), and then press Save file, a confirmation and audio preveiw will appear.\n",
        "4. Advanced Mode will give some more options, for a more professional and personalised result. Normal Mode is for quick test or non-professionals.\n",
        "\n",
        "BUGS: at the moment it is only possible to install and use EITHER AudioLDM2-Music and StableAudio Open OR MusicGen: If StableAudio and AudioLDM2 libraries are installed it is not possible to install audiocraft beacuse of \"NotImplementedError: A UTF-8 locale is required. Got ANSI_X3.4-1968\". tryed with\n",
        "\"import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\", \"!sudo locale-gen en_US.UTF-8\n",
        "!sudo update-locale\", but nothing solved the problem."
      ],
      "metadata": {
        "id": "CcO4m7ZeDDBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title INSTALL AudioLDM2-Music / StableAudio Open Music Generation Model & HuggingFace Login (1ST TIME) {\"vertical-output\":true,\"display-mode\":\"form\"}\n",
        "# install libraries for the generation model\n",
        "!pip install diffusers\n",
        "!pip install torchsde #required by diffusers\n",
        "\n",
        "\n",
        "# do the login in huggingface\n",
        "!huggingface-cli login\n",
        "#HuggingFace key:\n",
        "\n",
        "\n",
        "#TO-DO: need to make it automatic"
      ],
      "metadata": {
        "id": "aSWpdw5AmC8z",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title INSTALL MusicGen Music Generation Model (1ST TIME) {\"display-mode\":\"form\"}\n",
        "!pip install audiocraft #takes a while"
      ],
      "metadata": {
        "id": "KyuuQuGZnqeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP (1ST TIME)"
      ],
      "metadata": {
        "id": "M26Ux83geyRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install for \"user interface\"\n",
        "!pip install ipywidgets"
      ],
      "metadata": {
        "id": "PoK7_eOBee4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "4fefa0e4-05d9-44d3-bf24-3d5b27ac8e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install essentia for: bpm detection, key detection\n",
        "\n",
        "!pip install librosa\n",
        "# !pip install essentia"
      ],
      "metadata": {
        "id": "KWA34sMrtMYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90bd04ea-a0b0-414e-a811-4c46bd85d12e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install essentia-tensorflow for using Essentia models in general\n",
        "\n",
        "# unistall tensorflow if needed\n",
        "# !pip uninstall tensorflow -y\n",
        "\n",
        "!pip install essentia-tensorflow"
      ],
      "metadata": {
        "id": "6yJhA1heuP4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd3dc42-7ea1-432e-f992-575175b324f0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting essentia-tensorflow\n",
            "  Downloading essentia_tensorflow-2.1b6.dev1110-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from essentia-tensorflow) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from essentia-tensorflow) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from essentia-tensorflow) (6.0.2)\n",
            "Downloading essentia_tensorflow-2.1b6.dev1110-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.4/291.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: essentia-tensorflow\n",
            "Successfully installed essentia-tensorflow-2.1b6.dev1110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the TempoCNN model from essentia\n",
        "#YOU CAN DOWNLOAD THE WEIGHTS FOR OTHER TEMPOCNN MODELS HERE, k16 ones are more precise, using more resources:\n",
        "!wget https://essentia.upf.edu/models/tempo/tempocnn/deepsquare-k16-3.pb\n",
        "#!wget https://essentia.upf.edu/models/tempo/tempocnn/deeptemp-k4-3.pb\n",
        "#!wget https://essentia.upf.edu/models/tempo/tempocnn/deeptemp-k16-3.pb"
      ],
      "metadata": {
        "id": "Eu1v5tS8H3VM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "9d2098a3-5465-4cfa-a93c-c57b3061811b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-07 23:02:16--  https://essentia.upf.edu/models/tempo/tempocnn/deepsquare-k16-3.pb\n",
            "Resolving essentia.upf.edu (essentia.upf.edu)... 84.89.139.43\n",
            "Connecting to essentia.upf.edu (essentia.upf.edu)|84.89.139.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4833690 (4.6M) [application/octet-stream]\n",
            "Saving to: ‘deepsquare-k16-3.pb’\n",
            "\n",
            "deepsquare-k16-3.pb 100%[===================>]   4.61M   590KB/s    in 8.7s    \n",
            "\n",
            "2024-11-07 23:02:26 (540 KB/s) - ‘deepsquare-k16-3.pb’ saved [4833690/4833690]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download genre_discogs400 model weights\n",
        "!wget https://essentia.upf.edu/models/classification-heads/genre_discogs400/genre_discogs400-discogs-effnet-1.pb\n",
        "!wget https://essentia.upf.edu/models/music-style-classification/discogs-effnet/discogs-effnet-bs64-1.pb\n",
        "# download MTG-Jamendo genre model weights\n",
        "!wget https://essentia.upf.edu/models/classification-heads/mtg_jamendo_genre/mtg_jamendo_genre-discogs-effnet-1.pb\n",
        "\n",
        "# discogs400 metadata (contains genre lables column to decode embeddings)\n",
        "!wget https://essentia.upf.edu/models/classification-heads/genre_discogs400/genre_discogs400-discogs-effnet-1.json\n",
        "# mtg_jamendo metadata (contains genre lables column to decode embeddings)\n",
        "!wget https://essentia.upf.edu/models/classification-heads/mtg_jamendo_genre/mtg_jamendo_genre-discogs-effnet-1.json"
      ],
      "metadata": {
        "id": "JAEte1v8IsKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf68f216-b1c6-4b90-899c-494aa1da5cd4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-07 23:02:26--  https://essentia.upf.edu/models/classification-heads/genre_discogs400/genre_discogs400-discogs-effnet-1.pb\n",
            "Resolving essentia.upf.edu (essentia.upf.edu)... 84.89.139.43\n",
            "Connecting to essentia.upf.edu (essentia.upf.edu)|84.89.139.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2057977 (2.0M) [application/octet-stream]\n",
            "Saving to: ‘genre_discogs400-discogs-effnet-1.pb’\n",
            "\n",
            "genre_discogs400-di 100%[===================>]   1.96M   472KB/s    in 4.3s    \n",
            "\n",
            "2024-11-07 23:02:31 (472 KB/s) - ‘genre_discogs400-discogs-effnet-1.pb’ saved [2057977/2057977]\n",
            "\n",
            "--2024-11-07 23:02:31--  https://essentia.upf.edu/models/music-style-classification/discogs-effnet/discogs-effnet-bs64-1.pb\n",
            "Resolving essentia.upf.edu (essentia.upf.edu)... 84.89.139.43\n",
            "Connecting to essentia.upf.edu (essentia.upf.edu)|84.89.139.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18366619 (18M) [application/octet-stream]\n",
            "Saving to: ‘discogs-effnet-bs64-1.pb’\n",
            "\n",
            "discogs-effnet-bs64 100%[===================>]  17.52M   567KB/s    in 32s     \n",
            "\n",
            "2024-11-07 23:03:04 (559 KB/s) - ‘discogs-effnet-bs64-1.pb’ saved [18366619/18366619]\n",
            "\n",
            "--2024-11-07 23:03:05--  https://essentia.upf.edu/models/classification-heads/mtg_jamendo_genre/mtg_jamendo_genre-discogs-effnet-1.pb\n",
            "Resolving essentia.upf.edu (essentia.upf.edu)... 84.89.139.43\n",
            "Connecting to essentia.upf.edu (essentia.upf.edu)|84.89.139.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2803280 (2.7M) [application/octet-stream]\n",
            "Saving to: ‘mtg_jamendo_genre-discogs-effnet-1.pb’\n",
            "\n",
            "mtg_jamendo_genre-d 100%[===================>]   2.67M   575KB/s    in 5.3s    \n",
            "\n",
            "2024-11-07 23:03:11 (517 KB/s) - ‘mtg_jamendo_genre-discogs-effnet-1.pb’ saved [2803280/2803280]\n",
            "\n",
            "--2024-11-07 23:03:11--  https://essentia.upf.edu/models/classification-heads/genre_discogs400/genre_discogs400-discogs-effnet-1.json\n",
            "Resolving essentia.upf.edu (essentia.upf.edu)... 84.89.139.43\n",
            "Connecting to essentia.upf.edu (essentia.upf.edu)|84.89.139.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14951 (15K) [application/json]\n",
            "Saving to: ‘genre_discogs400-discogs-effnet-1.json’\n",
            "\n",
            "genre_discogs400-di 100%[===================>]  14.60K  61.8KB/s    in 0.2s    \n",
            "\n",
            "2024-11-07 23:03:12 (61.8 KB/s) - ‘genre_discogs400-discogs-effnet-1.json’ saved [14951/14951]\n",
            "\n",
            "--2024-11-07 23:03:12--  https://essentia.upf.edu/models/classification-heads/mtg_jamendo_genre/mtg_jamendo_genre-discogs-effnet-1.json\n",
            "Resolving essentia.upf.edu (essentia.upf.edu)... 84.89.139.43\n",
            "Connecting to essentia.upf.edu (essentia.upf.edu)|84.89.139.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4267 (4.2K) [application/json]\n",
            "Saving to: ‘mtg_jamendo_genre-discogs-effnet-1.json’\n",
            "\n",
            "mtg_jamendo_genre-d 100%[===================>]   4.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-07 23:03:13 (128 MB/s) - ‘mtg_jamendo_genre-discogs-effnet-1.json’ saved [4267/4267]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Essentia MTG-Jamendo mood and theme (56 classes) [WE ARE NOT GONNA USE THIS MODEL]\n",
        "# weigths:\n",
        "#!wget https://essentia.upf.edu/models/classification-heads/mtg_jamendo_moodtheme/mtg_jamendo_moodtheme-discogs-effnet-1.pb\n",
        "#json for classes:\n",
        "#!wget https://essentia.upf.edu/models/classification-heads/mtg_jamendo_moodtheme/mtg_jamendo_moodtheme-discogs-effnet-1.json\n",
        "\n",
        "#embedding model? always the same right?\n",
        "#!wget https://essentia.upf.edu/models/music-style-classification/discogs-effnet/discogs-effnet-bs64-1.pb"
      ],
      "metadata": {
        "id": "4bEuXd3zVPkk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Moods MIREX (29 classes in 5 mood clusters)\n",
        "\n",
        "#vggish\n",
        "# weigths:\n",
        "#!wget https://essentia.upf.edu/models/classification-heads/moods_mirex/moods_mirex-audioset-vggish-1.pb\n",
        "#json for classes:\n",
        "#!wget https://essentia.upf.edu/models/classification-heads/moods_mirex/moods_mirex-audioset-vggish-1.json\n",
        "# embedding:\n",
        "#!wget https://essentia.upf.edu/models/feature-extractors/vggish/audioset-vggish-3.pb\n",
        "\n",
        "#musicnn\n",
        "# weigths:\n",
        "!wget https://essentia.upf.edu/models/classification-heads/moods_mirex/moods_mirex-msd-musicnn-1.pb\n",
        "#json for classes:\n",
        "!wget https://essentia.upf.edu/models/classification-heads/moods_mirex/moods_mirex-msd-musicnn-1.json\n",
        "# embedding:\n",
        "!wget https://essentia.upf.edu/models/autotagging/msd/msd-musicnn-1.pb"
      ],
      "metadata": {
        "id": "OyfIIXuIWHBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b25330cb-5f9c-4583-a77b-68b9ab645d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-07 23:03:13--  https://essentia.upf.edu/models/classification-heads/moods_mirex/moods_mirex-msd-musicnn-1.pb\n",
            "Resolving essentia.upf.edu (essentia.upf.edu)... 84.89.139.43\n",
            "Connecting to essentia.upf.edu (essentia.upf.edu)|84.89.139.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95007 (93K) [application/octet-stream]\n",
            "Saving to: ‘moods_mirex-msd-musicnn-1.pb’\n",
            "\n",
            "moods_mirex-msd-mus 100%[===================>]  92.78K   218KB/s    in 0.4s    \n",
            "\n",
            "2024-11-07 23:03:15 (218 KB/s) - ‘moods_mirex-msd-musicnn-1.pb’ saved [95007/95007]\n",
            "\n",
            "--2024-11-07 23:03:15--  https://essentia.upf.edu/models/classification-heads/moods_mirex/moods_mirex-msd-musicnn-1.json\n",
            "Resolving essentia.upf.edu (essentia.upf.edu)... 84.89.139.43\n",
            "Connecting to essentia.upf.edu (essentia.upf.edu)|84.89.139.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2273 (2.2K) [application/json]\n",
            "Saving to: ‘moods_mirex-msd-musicnn-1.json’\n",
            "\n",
            "moods_mirex-msd-mus 100%[===================>]   2.22K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-07 23:03:16 (187 MB/s) - ‘moods_mirex-msd-musicnn-1.json’ saved [2273/2273]\n",
            "\n",
            "--2024-11-07 23:03:16--  https://essentia.upf.edu/models/autotagging/msd/msd-musicnn-1.pb\n",
            "Resolving essentia.upf.edu (essentia.upf.edu)... 84.89.139.43\n",
            "Connecting to essentia.upf.edu (essentia.upf.edu)|84.89.139.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3197999 (3.0M) [application/octet-stream]\n",
            "Saving to: ‘msd-musicnn-1.pb’\n",
            "\n",
            "msd-musicnn-1.pb    100%[===================>]   3.05M   593KB/s    in 5.9s    \n",
            "\n",
            "2024-11-07 23:03:23 (530 KB/s) - ‘msd-musicnn-1.pb’ saved [3197999/3197999]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [WE WON'T USE OPEN AI, IF IMPLEMENT A LLM FOR PROMPT SUGGESTION WILL BE ANOTHER ONE]\n",
        "# for requesting a suggestion on the instrument to generate,\n",
        "# based on the extracted data from music_in\n",
        "# !pip install openai"
      ],
      "metadata": {
        "id": "3ImuZ5KkfpjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the /content working directory\n",
        "import os\n",
        "os.chdir(\"/content\")\n",
        "print(\"Current working directory:\", os.getcwd()) # Verify the current working directory"
      ],
      "metadata": {
        "id": "FjnURWune4S5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c45693-44bb-495f-924c-7a69b0f8532c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### DEFINITION OF SOME USEFUL FUNCTIONS for extraction algorithms #####\n",
        "\n",
        "#import json and assign column to list, returns this list: THIS IS USED FOR DECODERS\n",
        "def list_classes_from_json(file_path, column_name):\n",
        "  import json\n",
        "  # Load the classes from the JSON file\n",
        "  with open(file_path, 'r') as f:\n",
        "      data = json.load(f)\n",
        "  # Extract the classes\n",
        "  list_classes = data[column_name]\n",
        "  # OUTPUT:\n",
        "  return list_classes\n",
        "\n",
        "\n",
        "#process audio for essentia\n",
        "def processed_audio_essentia(fileaudiopath):\n",
        "  from essentia.standard import MonoLoader\n",
        "  import librosa\n",
        "  # Load your audio file\n",
        "  y, sr = librosa.load(fileaudiopath)\n",
        "  # Process the audio\n",
        "  audio = MonoLoader(filename=fileaudiopath, sampleRate=sr, resampleQuality=4)()\n",
        "  # OUTPUT:\n",
        "  return audio\n",
        "\n",
        "#QUESTO SOTTO MI SA CHE NON SERVE!!!!!!\n",
        "#creates CSV of column1, column2 ES. filename | result\n",
        "def create_CSV(column1, column2, filename):\n",
        "  import csv\n",
        "  with open(filename, 'w', newline='') as csvfile:\n",
        "      writer = csv.writer(csvfile)\n",
        "      for item1, item2 in zip(column1, column2):\n",
        "        writer.writerow([item1, item2])"
      ],
      "metadata": {
        "id": "ePahFJNCl527"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### BPM EXTRACTION STAGE: TempoCNN (deepsquare-k16-3) #####\n",
        "#input loop to test with all the files\n",
        "\n",
        "BPM_model_path = \"/content/deepsquare-k16-3.pb\" #downloaded in installation stage\n",
        "\n",
        "def extract_BPM_TempoCNN(file_path):\n",
        "    from essentia.standard import MonoLoader, TempoCNN\n",
        "\n",
        "    import librosa\n",
        "    y, sr = librosa.load(file_path)\n",
        "\n",
        "    # Load an audio file\n",
        "    audio = MonoLoader(filename=file_path, sampleRate=sr, resampleQuality=4)()\n",
        "\n",
        "    model1 = TempoCNN(graphFilename=BPM_model_path)\n",
        "    global_tempo, local_tempo, local_tempo_probabilities = model1(audio)\n",
        "\n",
        "    return global_tempo\n"
      ],
      "metadata": {
        "id": "tf3-Z-UQmlvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### KEY EXTRACTION STAGE: Essentia KeyExtractor #####\n",
        "def extract_KEY_KeyExtractor(file_path):\n",
        "  import essentia.standard as es\n",
        "\n",
        "  # Load an audio file\n",
        "  audio = es.MonoLoader(filename=file_path)()\n",
        "\n",
        "  # Detect the key, scale\n",
        "  key_detector = es.KeyExtractor()\n",
        "  key, scale, strength = key_detector(audio)\n",
        "\n",
        "  return f\"{key} {scale} key\""
      ],
      "metadata": {
        "id": "NACY8D7LmtHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "##### GENRE EXTRACTION STAGE: Essentia discogs400 AND Essentia MTG-Jamendo #####\n",
        "# model weights and json dowloaded before in installation stage\n",
        "\n",
        "# Essentia genre_discogs400 (400 classes)\n",
        "def extract_GENRE_sorted_list_discogs400(file_path):\n",
        "    # PROCESS:\n",
        "    import numpy as np\n",
        "    from essentia.standard import MonoLoader, TensorflowPredictEffnetDiscogs, TensorflowPredict2D\n",
        "    import librosa\n",
        "    from collections import Counter\n",
        "\n",
        "    # Inputs: audio + labels\n",
        "    audio = processed_audio_essentia(file_path)\n",
        "    genres = list_classes_from_json(\"/content/genre_discogs400-discogs-effnet-1.json\", 'classes')\n",
        "\n",
        "    embedding_model = TensorflowPredictEffnetDiscogs(graphFilename=\"/content/discogs-effnet-bs64-1.pb\", output=\"PartitionedCall:1\")\n",
        "    embeddings = embedding_model(audio)\n",
        "\n",
        "    model = TensorflowPredict2D(graphFilename=\"/content/genre_discogs400-discogs-effnet-1.pb\", input=\"serving_default_model_Placeholder\", output=\"PartitionedCall:0\")\n",
        "    predictions = model(embeddings)\n",
        "\n",
        "    # Collect genre predictions\n",
        "    time_tags_list = []\n",
        "    # OUTPUT:\n",
        "    for i in range(0, len(predictions)):\n",
        "      time_tags_list.append(genres[np.argmax(predictions[i])])\n",
        "\n",
        "    # Count occurrences and sort genres by relevance\n",
        "    time_tags_list_count = Counter(time_tags_list)\n",
        "    genre_dict_sorted = dict(sorted(time_tags_list_count.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    # Extract only the genres in order of relevance as a list\n",
        "    suggested_genre_list = list(genre_dict_sorted.keys())\n",
        "\n",
        "    # Exclude specific genres (results from our research)\n",
        "    excluded_genres = {\"Electronic---Ambient\", \"Electronic---Experimental\", \"Electronic---Vaporwave\", \"Electronic---Downtempo\"}\n",
        "    suggested_genre_list = [genre for genre in genre_dict_sorted.keys() if genre not in excluded_genres]\n",
        "\n",
        "    return suggested_genre_list\n",
        "\n",
        "\n",
        "\n",
        "# Essentia MTG-Jamendo genre (87 classes)\n",
        "def extract_GENRE_sorted_list_mtg_jamendo(file_path):\n",
        "\n",
        "    # PROCESS:\n",
        "    import numpy as np\n",
        "    import librosa\n",
        "    from essentia.standard import MonoLoader, TensorflowPredictEffnetDiscogs, TensorflowPredict2D\n",
        "    from collections import Counter\n",
        "\n",
        "\n",
        "    audio = processed_audio_essentia(file_path)\n",
        "    genres = list_classes_from_json(\"/content/mtg_jamendo_genre-discogs-effnet-1.json\", 'classes')\n",
        "\n",
        "\n",
        "    embedding_model = TensorflowPredictEffnetDiscogs(graphFilename=\"/content/discogs-effnet-bs64-1.pb\", output=\"PartitionedCall:1\")\n",
        "    embeddings = embedding_model(audio)\n",
        "\n",
        "    model = TensorflowPredict2D(graphFilename=\"mtg_jamendo_genre-discogs-effnet-1.pb\")\n",
        "    predictions = model(embeddings)\n",
        "\n",
        "    # Collect genre predictions\n",
        "    time_tags_list = []\n",
        "    # OUTPUT:\n",
        "    for i in range(0, len(predictions)):\n",
        "      time_tags_list.append(genres[np.argmax(predictions[i])])\n",
        "\n",
        "    # Count occurrences and sort genres by relevance\n",
        "    time_tags_list_count = Counter(time_tags_list)\n",
        "    genre_dict_sorted = dict(sorted(time_tags_list_count.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    # Extract only the genres in order of relevance as a list\n",
        "    suggested_genre_list = list(genre_dict_sorted.keys())\n",
        "\n",
        "\n",
        "    # Exclude specific genres (results from our research)\n",
        "    excluded_genres = {\"ambient\", \"classical\"}\n",
        "    suggested_genre_list = [genre for genre in genre_dict_sorted.keys() if genre.lower() not in excluded_genres]\n",
        "\n",
        "\n",
        "    return suggested_genre_list\n"
      ],
      "metadata": {
        "id": "sU9yIMUy1JAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "##### MOOD EXTRACTION STAGE: Essentia MTG-Jamendo AND Essentia MIREX musicnn #####\n",
        "\n",
        "# Mood model for MTG-Jamendo [DONT USE IT!!!]\n",
        "def extract_MOOD_sorted_list_MTGJamendo(file_path):\n",
        "    import numpy as np\n",
        "    from essentia.standard import MonoLoader, TensorflowPredictEffnetDiscogs, TensorflowPredict2D\n",
        "    from collections import Counter\n",
        "\n",
        "    # Load audio and mood classes\n",
        "    audio = processed_audio_essentia(file_path)\n",
        "    moods = list_classes_from_json(\"/content/mtg_jamendo_moodtheme-discogs-effnet-1.json\", 'classes')\n",
        "\n",
        "    # Load and run embedding and mood prediction models\n",
        "    embedding_model = TensorflowPredictEffnetDiscogs(graphFilename=\"/content/discogs-effnet-bs64-1.pb\", output=\"PartitionedCall:1\")\n",
        "    embeddings = embedding_model(audio)\n",
        "\n",
        "    model = TensorflowPredict2D(graphFilename=\"/content/mtg_jamendo_moodtheme-discogs-effnet-1.pb\", input=\"serving_default_model_Placeholder\", output=\"PartitionedCall:0\")\n",
        "    predictions = model(embeddings)\n",
        "\n",
        "    # Collect predictions and count occurrences\n",
        "    time_tags_list = [moods[np.argmax(pred)] for pred in predictions]\n",
        "    time_tags_list_count = Counter(time_tags_list)\n",
        "    mood_dict_sorted = dict(sorted(time_tags_list_count.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    # Filter to include only tags from mood_tags_filtered_list\n",
        "    mood_tags_filtered_list = [\n",
        "        \"calm\", \"cool\", \"dream\", \"emotional\", \"energetic\",\n",
        "        \"fun\", \"funny\", \"groovy\", \"happy\", \"heavy\", \"hopeful\", \"inspiring\",\n",
        "        \"love\", \"meditative\", \"melancholic\", \"melodic\", \"motivational\",\n",
        "        \"positive\", \"powerful\", \"relaxing\", \"romantic\", \"sad\", \"sexy\", \"soft\",\n",
        "        \"upbeat\", \"uplifting\"\n",
        "    ]\n",
        "    filtered_mood_list = [tag for tag in mood_dict_sorted.keys() if tag in mood_tags_filtered_list]\n",
        "\n",
        "    return filtered_mood_list\n",
        "\n",
        "\n",
        "\n",
        "# Mood model for MIREX musicnn [USE THIS]\n",
        "def extract_MOOD_sorted_list_MIREX_musicnn(file_path):\n",
        "    import numpy as np\n",
        "    from essentia.standard import MonoLoader, TensorflowPredictMusiCNN, TensorflowPredict2D\n",
        "    from collections import Counter\n",
        "\n",
        "    # Load audio and mood classes\n",
        "    audio = processed_audio_essentia(file_path)\n",
        "    #moods = list_classes_from_json(\"/content/moods_mirex-msd-musicnn-1.json\", 'classes')\n",
        "    #these mood tags are too complex, we are going to use a new list that retain the same significance but is more functional for a music generation model:\n",
        "    moods = [\"Bold, Energetic\", \"Playful, Friendly\", \"Thoughtful, Melancholic\", \"whimsical, silly\", \"Intense, Fierce\"]\n",
        "\n",
        "    # Load and run embedding and mood prediction models\n",
        "    embedding_model = TensorflowPredictMusiCNN(graphFilename=\"/content/msd-musicnn-1.pb\", output=\"model/dense/BiasAdd\")\n",
        "    embeddings = embedding_model(audio)\n",
        "\n",
        "    model = TensorflowPredict2D(graphFilename=\"/content/moods_mirex-msd-musicnn-1.pb\", input=\"serving_default_model_Placeholder\", output=\"PartitionedCall\")\n",
        "    predictions = model(embeddings)\n",
        "\n",
        "    # Collect predictions and count occurrences\n",
        "    time_tags_list = [moods[np.argmax(pred)] for pred in predictions]\n",
        "    time_tags_list_count = Counter(time_tags_list)\n",
        "    mood_dict_sorted = dict(sorted(time_tags_list_count.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    return list(mood_dict_sorted.keys())\n"
      ],
      "metadata": {
        "id": "hCYyLjze1SrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "##### some functions for generation models #####\n",
        "\n",
        "#calculate the correct time-lenght for the loop given the bpm\n",
        "def audio_duration_BPM(bpm, beats):\n",
        "  n_beats = 32\n",
        "  one_beat_duration_given_bpm = 60/bpm\n",
        "  audio_duration = one_beat_duration_given_bpm * n_beats\n",
        "  return audio_duration\n",
        "\n",
        "\n",
        "\n",
        "def show_audio_box(file_path):\n",
        "  print(\"\\nHere is your new music loop! Coherent with your musical idea, ready to drag in the DAW.\")\n",
        "  from IPython.display import display, Audio\n",
        "  display(Audio(file_path))\n",
        "\n",
        "\n",
        "\n",
        "def show_download_button(file_path):\n",
        "    import ipywidgets as widgets\n",
        "    from IPython.display import display\n",
        "\n",
        "    # Create a button widget\n",
        "    download_button = widgets.Button(description=\"Download\", button_style='success')\n",
        "\n",
        "    # Define the function to run when the button is clicked\n",
        "    def on_button_click(b):\n",
        "        from google.colab import files\n",
        "        files.download(file_path)\n",
        "\n",
        "    # Attach the function to the button\n",
        "    download_button.on_click(on_button_click)\n",
        "\n",
        "    # Display the button\n",
        "    display(download_button)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### GENERATION MODELS #####\n",
        "\n",
        "def music_generation_AudioLDM2(prompt, num_inference_steps, audio_duration):\n",
        "  # AudioLDM2-Music w/ diffusers\n",
        "  # https://huggingface.co/cvssp/audioldm2-music\n",
        "\n",
        "  #generate\n",
        "  from diffusers import AudioLDM2Pipeline\n",
        "  import torch\n",
        "\n",
        "  repo_id = \"cvssp/audioldm2-music\"\n",
        "  pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch.float16)\n",
        "  pipe = pipe.to(\"cuda\")\n",
        "\n",
        "  audio = pipe(prompt, num_inference_steps=num_inference_steps, audio_length_in_s=audio_duration).audios[0]\n",
        "\n",
        "  #save\n",
        "  import scipy\n",
        "  filename = f'[AudioLDM2-Music] {prompt}.wav'\n",
        "  scipy.io.wavfile.write(filename, rate=16000, data=audio)\n",
        "\n",
        "  show_audio_box(filename)\n",
        "\n",
        "  show_download_button(filename)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def music_generation_StableAudioOpen(prompt, num_inference_steps, audio_duration, negative_prompt):\n",
        "  # StableAudio Open w/ diffusers\n",
        "\n",
        "  # PROCESS:\n",
        "  import torch\n",
        "  import soundfile as sf\n",
        "  from diffusers import StableAudioPipeline\n",
        "\n",
        "  pipe = StableAudioPipeline.from_pretrained(\"stabilityai/stable-audio-open-1.0\")\n",
        "  pipe = pipe.to(\"cuda\")\n",
        "\n",
        "  # create random seed for generator\n",
        "  import random\n",
        "  random_seed = random.randint(0, 9999)\n",
        "  generator = torch.Generator(\"cuda\").manual_seed(random_seed)\n",
        "\n",
        "  # run the generation\n",
        "  audio = pipe(\n",
        "      prompt,\n",
        "      negative_prompt=negative_prompt,\n",
        "      num_inference_steps=num_inference_steps,\n",
        "      audio_end_in_s = audio_duration, #audio duration calculated in the step before!!\n",
        "      num_waveforms_per_prompt=3,\n",
        "      generator=generator,\n",
        "  ).audios\n",
        "\n",
        "  # OUTPUT:\n",
        "  output = audio[0].T.float().cpu().numpy()\n",
        "  filename = f'[StableAudio Open] {prompt} [seed:{random_seed}].wav'\n",
        "  sf.write(filename, output, pipe.vae.sampling_rate)\n",
        "\n",
        "  show_audio_box(filename)\n",
        "\n",
        "  show_download_button(filename)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def music_generation_MusicGenStereoMedium(prompt, audio_duration):\n",
        "# MusicGen: musicgen-stereo-medium\n",
        "  import torchaudio\n",
        "  from audiocraft.models import MusicGen\n",
        "  from audiocraft.data.audio import audio_write\n",
        "\n",
        "  model = MusicGen.get_pretrained('facebook/musicgen-stereo-medium')\n",
        "  model.set_generation_params(duration=audio_duration)\n",
        "  description = [prompt]\n",
        "  wav = model.generate(description)\n",
        "\n",
        "  for idx, one_wav in enumerate(wav):\n",
        "      # Will save with loudness normalization at -14 db LUFS.\n",
        "      filename = f'[musicgen-stereo-medium] {prompt}'\n",
        "      audio_write(filename, one_wav.cpu(), model.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
        "\n",
        "      show_audio_box(filename + \".wav\")\n",
        "\n",
        "      show_download_button(filename)\n"
      ],
      "metadata": {
        "id": "jtabpx-X1ZxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numba librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpoPMHWD22M0",
        "outputId": "c3374335-6b5a-442f-edf6-698be9b2f437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.60.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.26.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PIPELINE"
      ],
      "metadata": {
        "id": "q56MF4ze10_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title UPLOAD {\"vertical-output\":true,\"display-mode\":\"form\"}\n",
        "\n",
        "from ipywidgets import FileUpload, Button\n",
        "from IPython.display import display\n",
        "\n",
        "# Create a FileUpload widget that accepts only one file\n",
        "upload = FileUpload(accept='.mp3, .wav', multiple=False)  # Accepts .mp3 and .wav files only\n",
        "\n",
        "# Function to handle button clicks\n",
        "def save_file(b):\n",
        "    # Save locally the uploaded file as \"music_in\"\n",
        "    if upload.value:\n",
        "        for name, file_info in upload.value.items():\n",
        "            content = file_info['content']  # Binary file data\n",
        "            with open(\"music_in.wav\", 'wb') as f:\n",
        "                f.write(content)\n",
        "            print(f\"File '{name}' has been saved to disk as 'music_in.wav'.\")\n",
        "\n",
        "            from IPython.display import display, Audio\n",
        "            display(Audio(input_music_in_path))\n",
        "\n",
        "# Button\n",
        "button_save_file = Button(description=\"Save file\")\n",
        "button_save_file.on_click(save_file)\n",
        "\n",
        "# Display the upload widget and the button\n",
        "display(upload)\n",
        "display(button_save_file)\n",
        "\n",
        "# INPUT STAGE\n",
        "input_music_in_path = '/content/music_in.wav' #music_in path\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VUyW5uSDdz4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Advanced Mode execution {\"display-mode\":\"form\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# INPUT STAGE\n",
        "input_music_in_path = '/content/music_in.wav' #music_in path\n",
        "# input_prompt will be taken in the UI\n",
        "input_negative_prompt = \"Low quality.\" # what u dont want from the generation, use \"Low quality.\" as default\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############### PART 1: FEATURE EXTRACTION ##############\n",
        "\n",
        "BPM = extract_BPM_TempoCNN(input_music_in_path)\n",
        "\n",
        "KEY = extract_KEY_KeyExtractor(input_music_in_path)\n",
        "\n",
        "\n",
        "# Extract the music genres from both the models\n",
        "GENRE_disco = extract_GENRE_sorted_list_discogs400(input_music_in_path)\n",
        "GENRE_jamendo = extract_GENRE_sorted_list_mtg_jamendo(input_music_in_path)\n",
        "# All the genre tags\n",
        "GENRE = GENRE_disco + GENRE_jamendo\n",
        "\n",
        "\n",
        "# MOOD = extract_MOOD_sorted_list_MTGJamendo(input_music_in_path)\n",
        "MOOD = extract_MOOD_sorted_list_MIREX_musicnn(input_music_in_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############### PART 2: CREATE PRE-FILLED UI ##############\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Sample lists of options for genre and mood\n",
        "genre_options = GENRE\n",
        "mood_options = MOOD\n",
        "\n",
        "# Default values for genre and mood\n",
        "# TO-DO: should adjust with Try, since if one of the list is empty, this will give error\n",
        "default_genre = genre_options[0]  # first element\n",
        "default_mood = mood_options[0]  # first element\n",
        "\n",
        "\n",
        "# Define the input fields\n",
        "input_prompt = widgets.Text(\n",
        "    value='synth pluck arpeggio, high pitched',\n",
        "    description='PROMPT:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "bpm_input = widgets.IntText(\n",
        "    value=BPM,  # default BPM value\n",
        "    description='BPM:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# button x2 bpm\n",
        "duplicate_button = widgets.Button(\n",
        "    description='x2',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='48px')\n",
        ")\n",
        "def duplicate_bpm(b):\n",
        "    bpm_input.value = bpm_input.value * 2\n",
        "duplicate_button.on_click(duplicate_bpm)\n",
        "\n",
        "\n",
        "# button /2 bpm\n",
        "divide_button = widgets.Button(\n",
        "    description='/2',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='48px')\n",
        ")\n",
        "def divide_bpm(b):\n",
        "    bpm_input.value = bpm_input.value / 2\n",
        "divide_button.on_click(divide_bpm)\n",
        "\n",
        "\n",
        "\n",
        "n_beats_input = widgets.IntText(\n",
        "    value=32,  # default number of beats to generate\n",
        "    description='N. BEATS:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "key_input = widgets.Text(\n",
        "    value=KEY,  # default key\n",
        "    description='KEY:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "\n",
        "# Allow the user to input a custom genre\n",
        "genre_input = widgets.Text(\n",
        "    value=default_genre,  # pre-fill with first element of the list\n",
        "    description='GENRE:',\n",
        "    placeholder='Type custom genre here...',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Allow the user to input a custom mood\n",
        "mood_input = widgets.Text(\n",
        "    value=default_mood,  # pre-fill with first element of the list\n",
        "    description='MOOD:',\n",
        "    placeholder='Type custom mood here...',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Define the genre selection with dropdown\n",
        "genre_dropdown = widgets.Dropdown(\n",
        "    options=genre_options,\n",
        "    value=default_genre,  # default genre\n",
        "    description='',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='100px')\n",
        ")\n",
        "\n",
        "# Define the mood selection with dropdown\n",
        "mood_dropdown = widgets.Dropdown(\n",
        "    options=mood_options,\n",
        "    value=default_mood,  # default mood\n",
        "    description='',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='100px')\n",
        ")\n",
        "\n",
        "# Define the model options\n",
        "model_options = widgets.ToggleButtons(\n",
        "    options=['StableAudio Open', 'MusicGen', 'AudioLDM2-Music'],\n",
        "    description='MODEL:',\n",
        "    button_style='',\n",
        "    tooltips=['StableAudio Open model', 'MusicGen model', 'AudioLDM2-Music model']\n",
        ")\n",
        "\n",
        "inference_steps_slider = widgets.IntSlider(\n",
        "    value=40,  # default value\n",
        "    min=10,     # minimum value\n",
        "    max=400,    # maximum value\n",
        "    step=1,     # step size\n",
        "    description='',\n",
        "    continuous_update=False,  # update on release\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "slider_box = widgets.HBox([\n",
        "    widgets.Label(value='Inference Steps:', layout=widgets.Layout(width='120px')),\n",
        "    inference_steps_slider\n",
        "])\n",
        "\n",
        "# Model descriptions\n",
        "model_descriptions = {\n",
        "    'StableAudio Open': \"(DEFAULT) StableAudio Open is the best model, allowing for hi-res audio at 44100 kHz. It excels at generating modern, single-instrument tracks, particularly for electronic music, but struggles with older niche/uncommon acoustic instruments and vintage sounds.\",\n",
        "    'MusicGen': \"MusicGen offers lower quality than StableAudio, struggles with single instrument generation but handles vintage sounds better. It occasionally generates glitches, which may be interesting for experimental audio loops. MusicGen don't take Infernce Steps as input.\",\n",
        "    'AudioLDM2-Music': \"AudioLDM2 has the lowest quality, often producing audio that sounds distant, somewhat uncanny, as if from a post-apocalyptic radio. This model is interesting for experimental contexts, but it struggles with single instrument clarity.\"\n",
        "}\n",
        "\n",
        "# Description area for model info\n",
        "model_description = widgets.Output()\n",
        "\n",
        "# Function to update model description based on selection\n",
        "def update_model_description(change):\n",
        "    model_description.clear_output()\n",
        "    with model_description:\n",
        "        print(model_descriptions[change['new']])\n",
        "\n",
        "# Bind model options to description update\n",
        "model_options.observe(update_model_description, names='value')\n",
        "\n",
        "# Update the text box when a selection is made from the dropdown\n",
        "def update_genre(change):\n",
        "    genre_input.value = change['new']\n",
        "\n",
        "def update_mood(change):\n",
        "    mood_input.value = change['new']\n",
        "\n",
        "# Bind the dropdown change events to update functions\n",
        "genre_dropdown.observe(update_genre, names='value')\n",
        "mood_dropdown.observe(update_mood, names='value')\n",
        "\n",
        "# function to run when the GENERATE button is clicked:\n",
        "def generate_output(b):\n",
        "    genre = genre_input.value if genre_input.value else genre_dropdown.value\n",
        "    mood = mood_input.value if mood_input.value else mood_dropdown.value\n",
        "    print(f\"Generating {input_prompt.value}\\nBPM: {bpm_input.value}\\nKey: {key_input.value}\\nGenre: {genre}\\nMood: {mood}\")\n",
        "\n",
        "    # audio duration\n",
        "    audio_duration = audio_duration_BPM(bpm_input.value, n_beats_input.value)\n",
        "    print(f\"Audio duration: {audio_duration}\")\n",
        "\n",
        "    # creazione del prompt\n",
        "    def prompt_complete(prompt, genre, mood, key, bpm):\n",
        "      return f\"{prompt}, solo, {genre}, {mood}, {key}, {bpm} BPM\"\n",
        "    prompt = prompt_complete(input_prompt.value, genre_input.value, mood_input.value, key_input.value, bpm_input.value)\n",
        "    print(prompt)\n",
        "\n",
        "    # inference steps\n",
        "    num_inference_steps = inference_steps_slider.value\n",
        "    print(num_inference_steps)\n",
        "\n",
        "\n",
        "    #SELEZIONE DEL MODELLO, RICHIAMO DELLA FUNZIONE DEL MODELLO, GENERAZIONE\n",
        "    generation_model_selection = model_options.value\n",
        "    print(generation_model_selection)\n",
        "\n",
        "    if generation_model_selection == \"MusicGen\":\n",
        "      music_generation_MusicGenStereoMedium(prompt, audio_duration)\n",
        "    elif generation_model_selection == \"AudioLDM2-Music\":\n",
        "      music_generation_AudioLDM2(prompt, num_inference_steps, audio_duration)\n",
        "    elif generation_model_selection == \"StableAudio Open\":\n",
        "      music_generation_StableAudioOpen(prompt, num_inference_steps, audio_duration, input_negative_prompt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create the GENERATE button\n",
        "generate_button = widgets.Button(description=\"GENERATE\")\n",
        "generate_button.on_click(generate_output)\n",
        "\n",
        "# Create horizontal layouts for genre and mood\n",
        "genre_hbox = widgets.HBox([genre_input, genre_dropdown])\n",
        "mood_hbox = widgets.HBox([mood_input, mood_dropdown])\n",
        "\n",
        "#bpm box to duplicate or divide\n",
        "bpm_hbox = widgets.HBox([bpm_input, duplicate_button, divide_button])\n",
        "\n",
        "# Display all the widgets\n",
        "display(input_prompt, bpm_hbox, n_beats_input, key_input, genre_hbox, mood_hbox, model_options, model_description, slider_box, generate_button)\n",
        "\n",
        "# Initialize description with the default selection\n",
        "with model_description:\n",
        "    print(model_descriptions[model_options.value])\n",
        "\n"
      ],
      "metadata": {
        "id": "bTN8r7K4fHZt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Normal Mode execution {\"display-mode\":\"form\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# INPUT STAGE\n",
        "input_music_in_path = '/content/music_in.wav' #music_in path\n",
        "# input_prompt will be taken in the UI\n",
        "input_negative_prompt = \"Low quality.\" # what u dont want from the generation, use \"Low quality.\" as default\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############### PART 1: FEATURE EXTRACTION ##############\n",
        "\n",
        "BPM = extract_BPM_TempoCNN(input_music_in_path)\n",
        "\n",
        "KEY = extract_KEY_KeyExtractor(input_music_in_path)\n",
        "\n",
        "# Assign genre considering that the list could be empty\n",
        "GENRE_jamendo_list = extract_GENRE_sorted_list_mtg_jamendo(input_music_in_path)\n",
        "try: GENRE = GENRE_jamendo_list[0]\n",
        "except IndexError: GENRE = \"\"\n",
        "# print(GENRE)\n",
        "\n",
        "# Assign mood considering that the list could be empty\n",
        "MOOD_mirex_list = extract_MOOD_sorted_list_MIREX_musicnn(input_music_in_path)\n",
        "try: MOOD = MOOD_mirex_list[0]\n",
        "except IndexError: MOOD = \"\"\n",
        "# print(MOOD)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############### PART 2: CREATE PRE-FILLED UI ##############\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Define the input fields\n",
        "input_prompt = widgets.Text(\n",
        "    value='synth pluck arpeggio, high pitched',\n",
        "    description='PROMPT:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "bpm_input = widgets.IntText(\n",
        "    value=BPM,  # default BPM value\n",
        "    description='BPM:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# button x2 bpm\n",
        "duplicate_button = widgets.Button(\n",
        "    description='x2',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='48px')\n",
        ")\n",
        "def duplicate_bpm(b):\n",
        "    bpm_input.value = bpm_input.value * 2\n",
        "duplicate_button.on_click(duplicate_bpm)\n",
        "\n",
        "\n",
        "# button /2 bpm\n",
        "divide_button = widgets.Button(\n",
        "    description='/2',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='48px')\n",
        ")\n",
        "def divide_bpm(b):\n",
        "    bpm_input.value = bpm_input.value / 2\n",
        "divide_button.on_click(divide_bpm)\n",
        "\n",
        "\n",
        "\n",
        "n_beats_input = widgets.IntText(\n",
        "    value=32,  # default number of beats to generate\n",
        "    description='N. BEATS:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "key_input = widgets.Text(\n",
        "    value=KEY,  # default key\n",
        "    description='KEY:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "\n",
        "inference_steps_slider = widgets.IntSlider(\n",
        "    value=40,  # default value\n",
        "    min=10,     # minimum value\n",
        "    max=400,    # maximum value\n",
        "    step=1,     # step size\n",
        "    description='',\n",
        "    continuous_update=False,  # update on release\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "slider_box = widgets.HBox([\n",
        "    widgets.Label(value='Inference Steps:', layout=widgets.Layout(width='120px')),  # Adjust width as needed\n",
        "    inference_steps_slider\n",
        "])\n",
        "\n",
        "\n",
        "# Define the function to run when the GENERATE button is clicked\n",
        "def generate_output(b):\n",
        "    genre = GENRE\n",
        "    mood = MOOD\n",
        "    print(f\"Generating {input_prompt.value}\\nBPM: {bpm_input.value}\\nKey: {key_input.value}\\nGenre: {genre}\\nMood: {mood}\")\n",
        "\n",
        "    # audio duration\n",
        "    audio_duration = audio_duration_BPM(bpm_input.value, n_beats_input.value)\n",
        "    print(f\"Audio duration: {audio_duration}\")\n",
        "\n",
        "    num_inference_steps=50\n",
        "\n",
        "    # creazione del prompt\n",
        "    def prompt_complete(prompt, genre, mood, key, bpm):\n",
        "      return f\"{prompt}, solo, {genre}, {mood}, {key}, {bpm} BPM\"\n",
        "    prompt = prompt_complete(input_prompt.value, GENRE, MOOD, key_input.value, bpm_input.value)\n",
        "    print(prompt)\n",
        "\n",
        "    music_generation_StableAudioOpen(prompt, num_inference_steps, audio_duration, input_negative_prompt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create the GENERATE button\n",
        "generate_button = widgets.Button(description=\"GENERATE\")\n",
        "generate_button.on_click(generate_output)\n",
        "\n",
        "\n",
        "#bpm box to duplicate or divide\n",
        "bpm_hbox = widgets.HBox([bpm_input, duplicate_button, divide_button])\n",
        "\n",
        "# Display all the widgets\n",
        "display(input_prompt, bpm_hbox, n_beats_input, key_input, generate_button)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vtptSkjIJCYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}